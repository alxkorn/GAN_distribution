{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape, Flatten, LeakyReLU, Activation, Dense, BatchNormalization\n",
    "\n",
    "import pygmo as pg\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,input_dim=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(sample, mu, sigma):\n",
    "    \"\"\"\n",
    "    Пока проверка на нормальность\n",
    "    \n",
    "    sample: list - выборка полученная от генератора\n",
    "    mu: float - среднее распределения\n",
    "    sigma: float - среднее квадратичное отклонение распределения\n",
    "    \"\"\"\n",
    "    pvalue = stats.ttest_ind(sample,np.random.normal(loc=mu,scale=sigma,size=1000))[1]\n",
    "    return 0.4 * (np.mean(sample) - mu)**2 + 0.4*(np.std(sample) - sigma)**2 - 0.2*pvalue\n",
    "    # return np.mean(sample) - mu, np.std(sample) - sigma, -pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary() # 1153 параметра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    def __init__(self, fit_func, dim=407050, lb=-1., rb=1.):\n",
    "        self.dim = dim\n",
    "        self.lb = lb\n",
    "        self.rb = rb\n",
    "        self.fit_func = fit_func\n",
    "        \n",
    "    def fitness(self, weights):\n",
    "        return self.fit_func(weights)\n",
    "\n",
    "    def get_bounds(self):\n",
    "        return (np.full((self.dim,), self.lb), np.full((self.dim,), self.rb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1000\n",
    "REAL_MEAN = 5.0\n",
    "REAL_STD = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func(weights):\n",
    "    # Раскидывает веса\n",
    "    weight_layer_one = np.array(weights[:32]).reshape(1,32)\n",
    "    weight_layer_two = np.array(weights[32:64]).reshape(32,)\n",
    "    weight_layer_three = np.array(weights[64:-65]).reshape(32,32)\n",
    "    weight_layer_four = np.array(weights[-65:-33]).reshape(32,)\n",
    "    weight_layer_five = np.array(weights[-33:-1]).reshape(32,1)\n",
    "    weight_layer_six = np.array(weights[-1:]).reshape(1,)\n",
    "\n",
    "    generator.set_weights([\n",
    "        weight_layer_one,\n",
    "        weight_layer_two,\n",
    "        weight_layer_three,\n",
    "        weight_layer_four,\n",
    "        weight_layer_five,\n",
    "        weight_layer_six\n",
    "    ])\n",
    "    \n",
    "    #\n",
    "    sample = generator.predict(np.random.random(SAMPLE_SIZE))\n",
    "    return discriminator(sample, REAL_MEAN,REAL_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prob = Problem(fit_func=fit_func, dim=1153, lb=-1., rb=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = pg.algorithm(pg.sga(gen = 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pg.population(my_prob, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = algo.evolve(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19928848])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.champion_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pop.champion_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_layer_one = np.array(weights[:32]).reshape(1,32)\n",
    "weight_layer_two = np.array(weights[32:64]).reshape(32,)\n",
    "weight_layer_three = np.array(weights[64:-65]).reshape(32,32)\n",
    "weight_layer_four = np.array(weights[-65:-33]).reshape(32,)\n",
    "weight_layer_five = np.array(weights[-33:-1]).reshape(32,1)\n",
    "weight_layer_six = np.array(weights[-1:]).reshape(1,)\n",
    "\n",
    "generator.set_weights([\n",
    "        weight_layer_one,\n",
    "        weight_layer_two,\n",
    "        weight_layer_three,\n",
    "        weight_layer_four,\n",
    "        weight_layer_five,\n",
    "        weight_layer_six\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = generator.predict(np.random.random(size=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5., 13., 10., 13.,  8., 12., 17., 19., 11., 18., 13., 17., 10.,\n",
       "        11., 20., 10., 13., 18., 23., 19., 14., 18., 21., 12., 12., 13.,\n",
       "        15.,  6., 21., 20.,  7., 13., 19., 10., 15., 12., 11., 15.,  4.,\n",
       "        13., 15., 12., 15.,  8.,  9., 23., 13., 10., 17., 12., 13., 10.,\n",
       "        13., 13., 12., 10., 12., 18., 12., 17., 15.,  9., 15., 10., 13.,\n",
       "        14., 14.,  8., 11., 10.,  7., 15., 18., 15., 11., 12., 15., 11.,\n",
       "        13., 14., 11., 16.,  8., 16.,  9.,  7., 11.,  9., 11.,  9., 11.,\n",
       "        13., 10., 13., 25., 12., 13., 14., 11., 15., 15., 16.,  7., 12.,\n",
       "        12.,  9.,  7., 14., 14.,  9., 11., 15., 12., 15., 15.,  9., 14.,\n",
       "        11., 18., 13., 11., 14., 11.,  9.,  9., 13., 11., 11.,  7., 12.,\n",
       "        14., 12., 14., 12.,  7., 10.,  9.,  9., 17., 18., 17., 15., 13.,\n",
       "        14., 23., 19., 13., 16.,  9., 27., 14., 14., 24., 14., 12., 16.,\n",
       "        11.,  9., 14.,  8., 11., 17., 15., 21., 12., 16., 14.,  7., 14.,\n",
       "        12., 12.,  7., 19., 18., 11., 12., 11.,  7.,  6., 11., 10.,  9.,\n",
       "        13., 17., 17., 20., 14., 12., 12., 17., 19., 11., 12., 16., 11.,\n",
       "        16.,  8., 10.,  9., 21., 12., 17., 15., 16., 17.,  8., 19., 14.,\n",
       "        15., 16., 12., 14., 14., 15., 11., 17., 13., 12., 16., 13., 14.,\n",
       "         7., 12., 10.,  9., 12., 13., 14.,  4., 14., 21., 13., 15., 10.,\n",
       "        11., 10., 16., 13., 12., 14., 16.,  9., 16., 16.,  6., 11., 18.,\n",
       "        10., 12., 13.,  9., 11., 16.,  9.,  8., 11., 11., 14., 15., 14.,\n",
       "        17.,  9.,  7.,  9., 16.,  6.,  8., 11., 10.,  7., 14., 13., 18.,\n",
       "        16., 22., 13., 12., 10., 15., 16., 19.,  7.,  8., 13., 14., 15.,\n",
       "        10., 13.,  9., 14.,  9.,  6., 11.,  4.,  9., 11., 11., 13.,  7.,\n",
       "         8., 12., 12.,  7.,  3., 10., 11.,  6., 15., 12.,  8.,  4., 18.,\n",
       "         9.,  8., 12.,  3., 19., 12., 10., 11., 12.,  9.,  8., 18.,  4.,\n",
       "        13., 11.,  8., 15., 15., 11.,  5.,  6.,  5.,  9., 10.,  8., 11.,\n",
       "        15., 13.,  7., 11., 11., 16., 11., 17.,  7., 15., 11.,  6.,  9.,\n",
       "         8.,  6., 12.,  4.,  4.,  4., 12., 11., 11.,  8., 10.,  9.,  4.,\n",
       "         8., 12.,  5.,  5.,  7.,  7.,  7., 10.,  8.,  9.,  5., 17.,  4.,\n",
       "         7., 16.,  7., 13., 10., 10.,  8.,  8.,  9.,  5.,  5.,  7., 13.,\n",
       "         5., 11., 12.,  4.,  8., 18.,  8.,  5.,  5.,  9.,  8.,  2.,  6.,\n",
       "         6., 12., 11., 11., 13.,  8.,  7.,  8.,  5.,  6.,  9.,  9.,  7.,\n",
       "         7., 10.,  9.,  9.,  3., 10., 13., 12.,  7.,  4.,  6.,  7., 10.,\n",
       "         7.,  3., 10., 12.,  5.,  8.,  9., 10.,  7.,  9., 10., 10., 10.,\n",
       "         5., 10.,  7., 10.,  7.,  7., 13.,  9.,  9., 14.,  5.,  5., 13.,\n",
       "        14., 12.,  7., 11., 11., 13.,  8., 14.,  6., 13.,  8., 12.,  8.,\n",
       "         9.,  8., 15., 11., 12., 12.,  7., 10., 12., 14., 11.,  8.,  7.,\n",
       "         7.,  8., 12., 10., 10.,  7., 11.,  6.,  9.,  8.,  6., 10.,  5.,\n",
       "         8.,  7.,  3., 11.,  9.,  9.,  5.,  5., 13., 11., 12.,  4.,  7.,\n",
       "        11.,  7.,  9.,  8.,  9.,  6.,  7.,  5., 10.,  7.,  6., 13.,  9.,\n",
       "         3.,  9., 12.,  6.,  5., 15.,  7., 14., 12., 13., 13.,  8.,  6.,\n",
       "         8.,  7., 11.,  7., 10., 10.,  7.,  7., 10.,  4.,  8., 10.,  6.,\n",
       "        12.,  9., 16.,  9., 10., 15.,  8.,  7.,  6., 15.,  7.,  5.,  9.,\n",
       "        10.,  8.,  8.,  5.,  5.,  6., 11.,  2.,  6.,  9., 14.,  7.,  7.,\n",
       "        12.,  7., 10.,  7.,  8.,  4.,  8.,  9., 11.,  8., 10.,  9.,  9.,\n",
       "        11.,  7.,  4., 12., 10.,  9.,  7.,  6., 11.,  7., 10.,  8.,  5.,\n",
       "         9.,  9.,  4., 15.,  9.,  8.,  9.,  7.,  7.,  4.,  8.,  9.,  5.,\n",
       "         5., 12.,  3.,  9.,  8.,  9.,  8.,  9., 10.,  5.,  9.,  7.,  6.,\n",
       "         8.,  8.,  5.,  5., 15.,  5., 10.,  7.,  6., 11., 10.,  8., 10.,\n",
       "         7.,  7.,  2.,  9.,  8.,  6.,  5., 10., 11., 10., 16.,  5.,  8.,\n",
       "        14.,  4.,  9.,  7., 14., 10., 10.,  4.,  8.,  9.,  8., 11.,  7.,\n",
       "         4.,  8., 12., 11.,  7.,  6.,  9.,  6., 13.,  7.,  9., 10.,  6.,\n",
       "         8.,  5., 11., 13.,  5.,  8.,  6.,  8.,  9.,  5.,  8.,  4., 10.,\n",
       "         7.,  3.,  5.,  6.,  7.,  8.,  6.,  3., 17.,  6., 11.,  5.,  8.,\n",
       "        10., 10.,  8.,  9., 11.,  8., 14.,  3.,  9., 10., 11.,  6., 17.,\n",
       "        10.,  9., 13., 14.,  6.,  7.,  8.,  7.,  7.,  9.,  9.,  7.,  9.,\n",
       "         5.,  5., 10.,  2.,  4.,  8.,  7., 13.,  5.,  6.,  8.,  7., 11.,\n",
       "         3.,  5.,  3.,  7.,  7.,  5.,  9.,  6., 11.,  3.,  8.,  8.,  6.,\n",
       "         6.,  5., 10.,  7.,  5.,  7., 11.,  6.,  4.,  3.,  7.,  9.,  9.,\n",
       "         6.,  2.,  6.,  9., 11., 12.,  2.,  9.,  7.,  7.,  7.,  7.,  3.,\n",
       "         9.,  5.,  6.,  9., 11.,  9.,  4., 11.,  4., 11.,  9.,  8.,  4.,\n",
       "         7.,  5.,  7., 10.,  9.,  7.,  8.,  5.,  9.,  7.,  8.,  3.,  8.,\n",
       "         3.,  8., 14.,  9.,  6.,  4.,  4., 11., 14.,  4., 13., 10., 13.,\n",
       "        11.,  8.,  7., 10., 11.,  6., 11., 16.,  4., 15., 10., 11., 11.,\n",
       "         7.,  7.,  7., 10.,  9., 10.,  9., 11.,  2., 15., 10., 10., 12.,\n",
       "         6., 11.,  9., 12.,  9., 15.,  9., 17.,  9.,  8.,  5.,  9.,  7.,\n",
       "         6., 13.,  9.,  7., 11., 11., 13.,  7.,  6.,  7.,  8.,  4., 11.,\n",
       "        11., 10., 13., 10., 10.,  8., 13.,  8.,  7., 10., 10.,  9., 10.,\n",
       "         8.,  6., 15., 14.,  6., 10., 11.,  9.,  7., 13., 18., 11., 11.,\n",
       "        13., 10., 10., 10.,  9.,  8.,  8.,  5., 11., 18.,  9.,  5., 11.,\n",
       "         7.,  9., 12., 10., 12.,  6.,  5., 14.,  2.,  7.,  8., 11., 13.,\n",
       "        16.,  9., 11., 11., 11., 13., 10.,  4., 13.,  8.,  8., 10., 17.,\n",
       "        16.,  7., 16.,  9.,  5.,  4.,  9., 10.,  3.,  5., 15., 11.,  8.,\n",
       "        12., 13., 10.,  6., 11.,  9., 13., 13.,  5.,  9.,  7.,  9., 12.,\n",
       "        10., 14., 11., 15., 11.,  9., 10.,  8.,  5., 11.,  8.,  5.,  5.,\n",
       "         7., 12., 14.,  8.,  3.,  9., 14., 13., 17.,  9., 15., 10.,  3.,\n",
       "         6.,  8., 15.,  4., 11., 10.,  7.,  2., 13., 15., 15.,  9.]),\n",
       " array([1.9463977, 1.9530987, 1.9597995, ..., 8.633955 , 8.640656 ,\n",
       "        8.647357 ], dtype=float32),\n",
       " <a list of 1000 Patch objects>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214694e7e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y,bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9382858276367188, 0.00015177621389739215)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(generator.predict(np.random.random(100))) \n",
    "# Тест на нормальность в принципе. При втором числе меньшк .01 или 0.05 можно не думать о том, что выборка из номарльного "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9826411008834839, 0.21230487525463104)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(np.random.normal(loc=10,scale=2,size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.9999999955332202, pvalue=0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.normal(loc=10,scale=2,size=100)\n",
    "normaled_data = (data - .0)/1.0\n",
    "stats.kstest(normaled_data,'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.4819017486673065, pvalue=0.6299717810516865)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Кажется надежнее просто смотреть на среднее и отклонение\n",
    "stats.ttest_ind(np.random.normal(loc=10,scale=2,size=100),np.random.normal(loc=10,scale=2,size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [.111,1.3344,.434,.543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44976213713473034"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
